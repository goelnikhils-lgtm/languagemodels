{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONYFX1R7DNa8ZeHiX6skWN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/goelnikhils-lgtm/languagemodels/blob/main/Memory_Agent_Leveraging_MongoDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Code for Storing Long Term Agent Memory using MongoDB\n",
        "#https://dev.to/mongodb/langgraph-with-mongodb-building-conversational-long-term-memory-for-intelligent-ai-agents-2pcn"
      ],
      "metadata": {
        "id": "CE8B9z7oqlhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langgraph langchain_voyageai\n",
        "!pip install langchain-mongodb\n",
        "!pip install langgraph-store-mongodb\n",
        "!pip install pymongo\n",
        "!pip install langgraph-checkpoint-mongodb\n",
        "!pip install -U langmem\n",
        "!python -m pip install \"pymongo[srv]\"\n",
        "!pip install langchain-mcp-adapters"
      ],
      "metadata": {
        "id": "Ntrik1iNJI62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#code for connecting to MongoDB running on cloud\n",
        "from pymongo.mongo_client import MongoClient\n",
        "from pymongo.server_api import ServerApi\n",
        "uri = \"mongodb+srv://goelnikhils_db_user:XLRI@nikhil.a8je1te.mongodb.net/?retryWrites=true&w=majority&appName=Nikhil\" # Replace <XLRI123> with your actual password\n",
        "# Create a new client and connect to the server\n",
        "client = MongoClient(uri, server_api=ServerApi('1'))\n",
        "# Send a ping to confirm a successful connection\n",
        "try:\n",
        "    client.admin.command('ping')\n",
        "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
        "except Exception as e:\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9mvRnS9j431",
        "outputId": "c2400e92-e254-4929-9540-eec423832a14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pinged your deployment. You successfully connected to MongoDB!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bLTiW-S2Zol"
      },
      "outputs": [],
      "source": [
        "#memory agent using MongoDB for memory\n",
        "import os\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.store.mongodb.base import MongoDBStore , VectorIndexConfig\n",
        "from langchain_voyageai import VoyageAIEmbeddings\n",
        "from pymongo import MongoClient # Import MongoClient here\n",
        "from google.colab import userdata\n",
        "os.environ[\"VOYAGE_API_KEY\"] = userdata.get(\"VOYAGE_API_KEY\")\n",
        "\n",
        "#Initialize MongoDB connection\n",
        "#client = MongoClient(\"mongodb://localhost:27017/\") # I connected to Mongo Atlas on cloud so .... this is not required\n",
        "db = client[\"Nikhil\"]\n",
        "collection = db[\"Nikhil\"]\n",
        "\n",
        "#create the store with vector search capabilities\n",
        "store = MongoDBStore(\n",
        "    collection=collection,\n",
        "    index_config = VectorIndexConfig(\n",
        "        fields = None,\n",
        "        filters = None,\n",
        "        dims = 1536,\n",
        "        embed = VoyageAIEmbeddings(model = \"voyage-3.5\")\n",
        "        ),\n",
        "auto_index_timeout = 70\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.checkpoint.mongodb import MongoDBSaver\n",
        "\n",
        "#initialize the checkpointer to save memories\n",
        "checkpointer = MongoDBSaver(\n",
        "    client,\n",
        "    db_name = \"memories\",\n",
        "    collection_name = \"thread_checkpoints\"\n",
        ")"
      ],
      "metadata": {
        "id": "tdJ8A26sF9jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Each conversation gets a unique thread ID\n",
        "config = {\"configurable\":{\"thread_id\":\"thread-a\"}}\n",
        "# the checkpointer saved automatically:\n",
        "# 1. Saves state after each interaction\n",
        "# 2. Loads previous state when thread resumes\n",
        "# 3. Maintains conversation context"
      ],
      "metadata": {
        "id": "P5BVxhKxGjiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#overall code\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langmem import create_manage_memory_tool, create_search_memory_tool\n",
        "def prompt(state,store):\n",
        "  \"\"\"Dynamic prompt that injects relevant memories\"\"\"\n",
        "  #Semantic search for relevant memories\n",
        "  memories= store.search(\n",
        "      (\"memories\",), #namespace\n",
        "      query = state[\"messages\"][-1].content, #Current user message\n",
        "  )\n",
        "  system_msg = f\"\"\"You are a shopping assitant with persistent memory.\n",
        "  ###relevant memories\n",
        "  <memories>\n",
        "  {memories}\n",
        "  </memories>\n",
        "  ###end memories\n",
        "  Use these memories to provide personalized responses.\"\"\"\n",
        "  return [{\"role\":\"system\",\"content\":system_msg}, *state[\"messages\"]]\n",
        "\n",
        "#Create the complete agent\n",
        "agent = create_react_agent(\n",
        "    \"openai:gpt-4o\",\n",
        "    prompt = lambda state: prompt(state,store), #inject memories into prompt\n",
        "    tools = [\n",
        "        create_manage_memory_tool(namespace=(\"memories\",)), #memory management\n",
        "        #search_products #Domain-specific tools\n",
        "    ], # Add comma here\n",
        "    store = store, #Long-term memory storage\n",
        "    checkpointer = checkpointer, #Conversation persistence\n",
        ")"
      ],
      "metadata": {
        "id": "loZsC2uvIxMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#overall complete code for a agent starts here\n",
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.setLevel(logging.ERROR)\n",
        "\n",
        "from langchain.tools import tool\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_mongodb.vectorstores import MongoDBAtlasVectorSearch\n",
        "from langgraph.store.mongodb.base import MongoDBStore , VectorIndexConfig\n",
        "from langgraph.checkpoint.mongodb import MongoDBSaver\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langmem import create_manage_memory_tool, create_search_memory_tool\n",
        "from langchain_voyageai import VoyageAIEmbeddings # Import VoyageAIEmbeddings\n",
        "\n",
        "def create_shopping_agent():\n",
        "  \"\"\"Complete shopping assistant with memory\"\"\"\n",
        "  #Memory storage setup\n",
        "  store = MongoDBStore(\n",
        "      collection = client.memories.user_preferences,\n",
        "      index_config = VectorIndexConfig(\n",
        "          fields = [\"content\"],\n",
        "          filters = [\"active\"],\n",
        "          dims = 1536,\n",
        "          embed = VoyageAIEmbeddings(model = \"voyage-3.5\")\n",
        "      )\n",
        "  )\n",
        "  #conversation persistence\n",
        "  checkpointer = MongoDBSaver(\n",
        "      client,\n",
        "      db_name =\"Nikhil\",\n",
        "      collection_name = \"Nikhil\"\n",
        "  )\n",
        "\n",
        "  @tool\n",
        "  def search_products(query:str)->str:\n",
        "    \"\"\"search the product in the database using vector search\"\"\"\n",
        "    global client # Declare client as global\n",
        "    db = client[\"Nikhil\"]\n",
        "    collection = db[\"Nikhil\"]\n",
        "    # Use VoyageAIEmbeddings for querying to match indexing dimensions\n",
        "    vectorstore = MongoDBAtlasVectorSearch(collection, VoyageAIEmbeddings(model = \"voyage-3.5\"),text_key=\"title\",embedding_key =\"embedding\")\n",
        "    docs = vectorstore.similarity_search(query,k=5)\n",
        "    return \"\\n\".join([str(doc.metadata) for doc in docs])\n",
        "\n",
        "\n",
        "  #Dynamic Prompt with memory injection\n",
        "  def prompt(state,store):\n",
        "    \"\"\"Dynamic prompt that injects relevant memories\"\"\"\n",
        "    #Semantic search for relevant memories\n",
        "    user_query = state[\"messages\"][-1].content\n",
        "    memories= store.search(\n",
        "        (\"preferences\",), #namespace\n",
        "        query = user_query,\n",
        "        limit = 3,\n",
        "        filter = {\"active\":True}\n",
        "    )\n",
        "\n",
        "    #Search for relevant past interactions\n",
        "    purchase_history = store.search(\n",
        "        (\"purchases\",),\n",
        "        query = user_query,\n",
        "        limit = 3,\n",
        "    )\n",
        "    system_msg = f\"\"\"You are an expert shopping assitant with access to:\n",
        "    -Product Search Capabilities\n",
        "    -User preference memory\n",
        "    -Purchase History\n",
        "    ##User Preferences\n",
        "    {memories}\n",
        "    ## Recent Purchase History\n",
        "    {purchase_history}\n",
        "    ###end memories\n",
        "    Use these memories to provide personalized responses.\"\"\"\n",
        "    return [{\"role\":\"system\",\"content\":system_msg}, *state[\"messages\"]]\n",
        "\n",
        "  #Create Agent with all capabilities\n",
        "  return create_react_agent(\n",
        "      \"openai:gpt-4o\",\n",
        "      prompt = lambda state: prompt(state,store),\n",
        "      tools = [\n",
        "          create_manage_memory_tool(namespace=(\"preferences\",)),\n",
        "          create_search_memory_tool(namespace=(\"purchases\",)),\n",
        "          search_products\n",
        "      ],\n",
        "      store = store,\n",
        "      checkpointer = checkpointer,\n",
        "  )\n",
        "\n",
        "agent = create_shopping_agent()\n",
        "\n",
        "def get_user_config(user_id, thread_id=\"default_thread\"):\n",
        "    return {\"configurable\": {\"user_id\": user_id, \"thread_id\": thread_id}}\n",
        "\n",
        "\n",
        "# Conversation 1: Learning preferences\n",
        "config = get_user_config(\"user123\")\n",
        "response = agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"I'm vegan and prefer organic products\"}]\n",
        "}, config=config)\n",
        "\n",
        "print(response[\"messages\"][-1].content)\n",
        "\n",
        "# Conversation 2: Using learned preferences (different session)\n",
        "config = get_user_config(\"user123\", \"mobile-app\")\n",
        "response = agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Find me some pasta options\"}]\n",
        "}, config=config)\n",
        "# Agent automatically applies vegan + organic filters\n",
        "\n",
        "print(response[\"messages\"][-1].content)"
      ],
      "metadata": {
        "id": "QAlvJe0-u_tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22777b75"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}