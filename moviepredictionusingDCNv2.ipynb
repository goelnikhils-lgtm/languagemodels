{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGt2yvjn5iPTDdn4HmM5cq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/goelnikhils-lgtm/languagemodels/blob/main/moviepredictionusingDCNv2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pandas numpy matplotlib seaborn tqdm scikit-learn imbalanced-learn torch"
      ],
      "metadata": {
        "id": "Pn0tY9_f5m3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AT-TK3YZ5JoH"
      },
      "outputs": [],
      "source": [
        "#code for calculating CTR for the movie lens dataset\n",
        "\"\"\" core libraries\"\"\"\n",
        "import os , zipfile , requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "\n",
        "\"\"\" machine learning libraries\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset , DataLoader\n",
        "from sklearn.preprocessing import StandardScaler , OneHotEncoder , LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score , accuracy_score , classification_report , confusion_matrix\n",
        "from sklearn.manifold import TSNE\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "\n",
        "#enviornment setup\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"0\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"using device : {device}\")\n",
        "\n",
        "#data preparation\n",
        "print(\"----Step 1 : Preparing Movielens 1M Data----\")\n",
        "if not os.path.exists(\"ml-1m.zip\"):\n",
        "    print(\"Downloading movielens 1M dataset...\")\n",
        "    os.system(\"wget -q https://files.grouplens.org/datasets/movielens/ml-1m.zip\")\n",
        "    os.system(\"unzip -q ml-1m.zip\")\n",
        "    print(\"Download complete.\")\n",
        "#load data\n",
        "print(\"Loading data...\")\n",
        "data_dir = \"ml-1m\" # Corrected data directory\n",
        "ratings = pd.read_csv(os.path.join(data_dir, \"ratings.dat\"), sep=\"::\", engine=\"python\", names=[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"])\n",
        "users = pd.read_csv(os.path.join(data_dir, \"users.dat\"), sep=\"::\", engine=\"python\", names=[\"UserID\", \"Gender\", \"Age\", \"Occupation\", \"Zip-code\"])\n",
        "movies = pd.read_csv(os.path.join(data_dir, \"movies.dat\"), sep=\"::\", engine=\"python\", names=[\"MovieID\", \"Title\", \"Genres\"], encoding='latin-1')\n",
        "\n",
        "#merge data\n",
        "print(\"Merging data...\")\n",
        "#data frame a tabular data frame\n",
        "df = ratings.merge(users, on=\"UserID\").merge(movies, on=\"MovieID\")\n",
        "\n",
        "#create binary target variable(1 if rating >=4 , else 0)\n",
        "df['Target'] = (df['Rating'] >= 4).astype(int)\n",
        "\n",
        "#encode numerical features\n",
        "print(\"Encoding features...\")\n",
        "encoders = {}\n",
        "categorical_features = [\"UserID\", \"MovieID\", \"Gender\", \"Occupation\", \"Age\"]\n",
        "for feature in categorical_features:\n",
        "    encoders[feature] = LabelEncoder()\n",
        "    df[feature] = encoders[feature].fit_transform(df[feature])\n",
        "\n",
        "#dataset shape\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Target Distribution:{df['Target'].value_counts(normalize=True)}\")\n",
        "\n",
        "#--- DCNV2 model preparation ---\n",
        "class CrossLayerV2(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(CrossLayerV2, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.weight = nn.Parameter(torch.randn(input_dim, input_dim))\n",
        "        self.bias = nn.Parameter(torch.zeros(input_dim)) # Bias should be a vector\n",
        "\n",
        "    def forward(self, x0, xl):\n",
        "        # x0: original input, xl: output from previous layer\n",
        "        # Element-wise multiplication and addition\n",
        "        # matrix based cross layer : xl+1 = x0 * (xl @ W) + b + xl\n",
        "        return x0 * (torch.matmul(xl, self.weight) + self.bias) + xl\n",
        "\n",
        "\n",
        "class DCNv2(nn.Module):\n",
        "    def __init__(self, feature_dims, embedding_dim=16, num_cross_layers=3, deep_layers=[512, 256, 128]):\n",
        "        super(DCNv2, self).__init__()\n",
        "\n",
        "        # Embedding layers for each feature\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            feature: nn.Embedding(dim, embedding_dim) for feature, dim in feature_dims.items()\n",
        "        })\n",
        "        #input dimensions for cross and deep networks\n",
        "        input_dim = len(feature_dims) * embedding_dim\n",
        "\n",
        "        # Cross Network V2 Matrix based\n",
        "        self.cross_layers = nn.ModuleList()\n",
        "        for _ in range(num_cross_layers):\n",
        "            self.cross_layers.append(CrossLayerV2(input_dim)) # Instantiate CrossLayerV2\n",
        "\n",
        "        #deep network\n",
        "        deep_input_dim = input_dim\n",
        "        self.deep_layers = nn.ModuleList()\n",
        "        for hidden_dim in deep_layers:\n",
        "            self.deep_layers.append(nn.Linear(deep_input_dim, hidden_dim))\n",
        "            deep_input_dim = hidden_dim\n",
        "\n",
        "        #final output layer\n",
        "        final_dim = input_dim + deep_layers[-1] #cross network output + deep network output\n",
        "        self.output_layer = nn.Linear(final_dim, 1)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #get embeddings\n",
        "        embeddings = []\n",
        "        for feature, emb_layer in self.embeddings.items():\n",
        "            embeddings.append(emb_layer(x[feature]))\n",
        "\n",
        "        x0 = torch.cat(embeddings, dim=1) #concatenate all embeddings\n",
        "\n",
        "        # Cross Network V2 forward pass\n",
        "        xl = x0\n",
        "        for layer in self.cross_layers:\n",
        "            xl = layer(x0,xl)  # Use instantiated layer\n",
        "\n",
        "        # Deep Network forward pass\n",
        "        deep_out = x0\n",
        "        for layer in self.deep_layers:\n",
        "            deep_out = F.relu(layer(deep_out))\n",
        "            deep_out = self.dropout(deep_out)\n",
        "\n",
        "        # Concatenate cross and deep outputs\n",
        "        combined = torch.cat([xl, deep_out], dim=1)\n",
        "\n",
        "        # Final output layer\n",
        "        out = torch.sigmoid(self.output_layer(combined))\n",
        "        return out\n",
        "\n",
        "\n",
        "#data set class\n",
        "class MovieLensDataset(Dataset):\n",
        "        def __init__(self, dataframe, categorical_features):\n",
        "            self.data = {}  # Initialize self.data as a dictionary\n",
        "            for feature in categorical_features:\n",
        "                self.data[feature] = torch.LongTensor(dataframe[feature].values)\n",
        "            self.target = torch.FloatTensor(dataframe['Target'].values)\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.target)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            sample = {feature: self.data[feature][idx] for feature in self.data}\n",
        "            return sample, self.target[idx]\n",
        "\n",
        "# 4 training step\n",
        "#split data\n",
        "print(\"Splitting data...\")\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['Target'], random_state=42)\n",
        "#feature dimenions\n",
        "feature_dims = {\n",
        "  \"UserID\": df['UserID'].nunique(),\n",
        "  \"MovieID\": df['MovieID'].nunique(),\n",
        "  \"Gender\": df['Gender'].nunique(),\n",
        "  \"Age\": df['Age'].nunique(),\n",
        "  \"Occupation\": df['Occupation'].nunique()\n",
        "}\n",
        "\n",
        "#create datasets and dataloaders\n",
        "train_dataset = MovieLensDataset(train_df, categorical_features)\n",
        "test_dataset = MovieLensDataset(test_df, categorical_features)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
        "\n",
        "#intialize model , loss function and optimizer\n",
        "model = DCNv2(feature_dims, embedding_dim=16, num_cross_layers=3, deep_layers=[512, 256, 128]).to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "\n",
        "print(\"Model intialized with {sum(p.numel() for p in model.parameters() if p.requires_grad)} trainable parameters\")\n",
        "\n",
        "#training function\n",
        "num_epochs = 25\n",
        "train_loss=[]\n",
        "test_auc = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    #training\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    num_batches = 0\n",
        "    for batch_data , batch_targets in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n",
        "        #move to device\n",
        "        batch_data = {k: v.to(device) for k, v in batch_data.items()}\n",
        "        batch_targets = batch_targets.to(device)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_data).squeeze()\n",
        "        loss = criterion(outputs, batch_targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        num_batches += 1\n",
        "    avg_train_loss = epoch_loss / num_batches\n",
        "    train_loss.append(avg_train_loss)\n",
        "\n",
        "#Evaluation\n",
        "model.eval()\n",
        "all_predictions = []\n",
        "all_targets = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_data, batch_targets in tqdm(test_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Evaluating\"):\n",
        "        batch_data = {k: v.to(device) for k, v in batch_data.items()}\n",
        "        outputs = model(batch_data).squeeze()\n",
        "        all_predictions.extend(outputs.cpu().numpy())\n",
        "        all_targets.extend(batch_targets.numpy())\n",
        "    test_auc_score = roc_auc_score(all_targets, all_predictions)\n",
        "    test_auc.append(test_auc_score)\n",
        "\n",
        "print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Test AUC: {test_auc_score:.4f}\")\n",
        "\n",
        "#step 5 visualizing\n",
        "print(\"----Step 5 : Visualizing Training Progress----\")\n",
        "\n",
        "#plot training loss and test AUC\n",
        "fig , (ax1,ax2) = plt.subplots(1,2,figsize=(12,5))\n",
        "\n",
        "#training loss\n",
        "ax1.plot(range(1,num_epochs+1),train_loss,label=\"Train Loss\",color='blue')\n",
        "ax1.set_title(\"Training Loss over Epochs\")\n",
        "ax1.set_xlabel(\"Epochs\")\n",
        "ax1.set_ylabel(\"Binary Cross Entropy Loss\")\n",
        "ax1.grid(True,alpha=0.3)\n",
        "\n",
        "#test AUC\n",
        "ax2.plot(range(1,num_epochs+1),test_auc,label=\"Test AUC\",color='green')\n",
        "ax2.set_title(\"Test AUC over Epochs\")\n",
        "ax2.set_xlabel(\"Epochs\")\n",
        "ax2.set_ylabel(\"AUC Score\")\n",
        "ax2.grid(True,alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#visualizing emnbeddings using t-SNE\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  user_embeddings = model.embeddings['UserID'].weight.cpu().numpy()\n",
        "  movie_embeddings = model.embeddings['MovieID'].weight.cpu().numpy()\n",
        "\n",
        "#sample subset for visualization\n",
        "n_samples = min(500, len(user_embeddings))\n",
        "user_sample = np.random.choice(len(user_embeddings), n_samples, replace=False)\n",
        "movie_sample = np.random.choice(len(movie_embeddings), n_samples, replace=False)\n",
        "\n",
        "#apply t-sne\n",
        "user_tsne = TSNE(n_components=2, random_state=42).fit_transform(user_embeddings[user_sample])\n",
        "movie_tsne = TSNE(n_components=2, random_state=42).fit_transform(movie_embeddings[movie_sample])\n",
        "\n",
        "#plot embeddings\n",
        "fig , (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "\n",
        "#user embeddings\n",
        "scattter_1 = ax1.scatter(user_tsne[:,0], user_tsne[:,1], c=user_sample, cmap= \"virdis\", alpha=0.6)\n",
        "ax1.set_title(\"User Embeddings t-SNE\")\n",
        "ax1.set_xlabel(\"t-SNE Component 1\")\n",
        "ax1.set_ylabel(\"t-SNE Component 2\")\n",
        "plt.colorbar(scattter_1, ax=ax1, label=\"User ID\")\n",
        "\n",
        "#movie embeddings\n",
        "scattter_2 = ax2.scatter(movie_tsne[:,0], movie_tsne[:,1], c=movie_sample, cmap=\"plasma\", alpha=0.6)\n",
        "ax2.set_title(\"Movie Embeddings t-SNE\")\n",
        "ax2.set_xlabel(\"t-SNE Component 1\")\n",
        "ax2.set_ylabel(\"t-SNE Component 2\")\n",
        "plt.colorbar(scattter_2, ax=ax2, label=\"Movie ID\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#final result summary\n",
        "print(\"----Step 6 : Final Evaluation on Test Set----\")\n",
        "print(f\"Final Test AUC: {test_auc[-1]:.4f}\")\n",
        "print(f\"Best Test AUC: {max(test_auc):.4f}\")\n",
        "print(f\"User Embedding Shape: {user_embeddings.shape}\")\n",
        "print(f\"Movie Embedding Shape: {movie_embeddings.shape}\")"
      ]
    }
  ]
}