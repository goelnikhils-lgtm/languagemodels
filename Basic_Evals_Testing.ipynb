{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1szNWyak+ln4o9CaU0b5R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/goelnikhils-lgtm/languagemodels/blob/main/Basic_Evals_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBTx5h6eZcji"
      },
      "outputs": [],
      "source": [
        "# writing a simple eval\n",
        "#we need to try with PyTest\n",
        "#two kind of evals - Reference Free and Reference(where GT is available)\n",
        "#Online and offline Evals\n",
        "#Credit -> https://www.youtube.com/watch?v=-zoIqOpt2DA&list=PL9omX6impEuNTr0KGLChHwhvN-q3ZF12d&index=5\n",
        "#Credit -> https://www.youtube.com/watch?v=IMN_bDVRZ1M&list=PLrLEqwuz-mRI5ubqVJ7DpbHheCflJDDXk&index=7\n",
        "#Credit -> https://www.geeksforgeeks.org/nlp/perplexity-for-llm-evaluation/\n",
        "#Calculate Context Retreival Effectiveness via metrics such as Contextual Recall , Precision\n",
        "#use BERTScore for this\n",
        "#challenge is that BERT Score will not work for long sentences as BERT has context window of size = 512 .. then what to use\n",
        "#BERTScore - Measures the semantic similarity of the two sentences. Higher score indicates better match\n",
        "#BLEU (Precision) metric is used for evaluating transalation. Tokens generated by model match with ground truth. Higher score indicates better match\n",
        "#ROUGE is used to evaluate text summarization - Recall Oriented Unigram Gist Evaluation ->#Objective of ROUGE is to measure /evaluate the longest (unigram , bigram , n-gram etc.)overlap between the generated text and reference text in terms of unigrams. Higher means the better\n",
        "#Perplexity - Metric to measure the answer coherence of LLM . LLM generated text .... Lower perplexity means LLM is generating a coherent response\n",
        "#Diversity - Metric to measure the diversity in the generated text . Higher diversity means large vocab of LLM and that this is good . Formula is unique-n-grams/total n-grams\n",
        "#Racial Bias - Offensive Language\n",
        "#WEAT\n",
        "#Fact Checking Algos\n",
        "#Burstiness"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from openai import OpenAI\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Literal\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# load_dotenv() # No longer needed as we are using Colab secrets\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "# Access the API key from Colab's secrets manager\n",
        "openai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "\n",
        "client = OpenAI(api_key=openai_api_key)"
      ],
      "metadata": {
        "id": "Glvk6QiKZqj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d096a80"
      },
      "source": [
        "To use the OpenAI API, you'll need an API key. If you don't already have one, you can generate one from the [OpenAI website](https://beta.openai.com/account/api-keys).\n",
        "\n",
        "In Colab, add the key to the secrets manager under the \"ðŸ”‘\" icon in the left panel. Give it the name `OPENAI_API_KEY`. Then, you can access it in your code like this:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_event(filename:str) ->dict:\n",
        "  with open(filename) as f:\n",
        "    return json.load(f)\n",
        "\n",
        "class CustomerInquiry(BaseModel):\n",
        "  category:Literal[\"complaint\",\"feature_request\",\"billing\",\"other\"]\n",
        "  response:str\n",
        "def process_customer_message(message:str) -> CustomerInquiry:\n",
        "  response = client.responses.parse(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    text_format = CustomerInquiry,\n",
        "    input = [\n",
        "        {\n",
        "            \"role\":\"system\",\n",
        "            \"content\":\"You are a customer serivce assistant that analyzes customer inquiries\"\n",
        "        },\n",
        "        {\n",
        "            \"role\":\"user\",\n",
        "            \"content\":message\n",
        "        }\n",
        "\n",
        "    ]\n",
        "  )\n",
        "  return response.output_parsed"
      ],
      "metadata": {
        "id": "FFZ0azH9Z7JA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_billing_categorization():\n",
        "  event = \"I need help with my billing\"\n",
        "  result = process_customer_message(event)\n",
        "  assert result.category == \"other\"\n",
        "  assert (len(result.response)) >10\n",
        "\n",
        "\n",
        "def test_feature_request_categorization():\n",
        "  event = \"I would like to request a new feature\"\n",
        "  result = process_customer_message(event)\n",
        "  assert result.category == \"feature_request\"\n",
        "  assert (len(result.response)) >10\n",
        "\n",
        "def test_complaint_categorization():\n",
        "  event = \"I am very unhappy with the service\"\n",
        "  result = process_customer_message(event)\n",
        "  assert result.category == \"complaint\"\n",
        "  assert (len(result.response)) >5\n",
        "\n",
        "#run all tests\n",
        "if __name__ == \"__main__\":\n",
        "  tests =[\n",
        "    test_billing_categorization,\n",
        "    test_feature_request_categorization,\n",
        "    test_complaint_categorization # Corrected function name\n",
        "  ]\n",
        "  passed = 0\n",
        "  for test in tests:\n",
        "    try:\n",
        "      test()\n",
        "      print(f\"{test.__name__}: Passed\")\n",
        "      passed += 1\n",
        "    except AssertionError as e:\n",
        "      print(f\"{test.__name__}: Failed - {e}\")\n",
        "  print(f\"\\nResults: {passed}/{len(tests)} tests passed\")"
      ],
      "metadata": {
        "id": "L9P41rwccYvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Eval Tutorial from Evidently\n",
        "!pip install evidently[llm]"
      ],
      "metadata": {
        "id": "h_O_psz20uCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from evidently import Report\n",
        "from evidently import Dataset , DataDefinition\n",
        "from evidently.descriptors import TextLength , Sentiment , HuggingFace , IncludesWords , SemanticSimilarity , ExactMatch , BERTScore , SentenceCount\n",
        "from evidently.descriptors import LLMEval , PIILLMEval, DeclineLLMEval, CorrectnessLLMEval , FaithfulnessLLMEval, DeclineLLMEval, ContextQualityLLMEval\n",
        "from evidently.descriptors import ColumnTest, TestSummary, CustomColumnDescriptor\n",
        "from evidently.llm.templates import BinaryClassificationPromptTemplate, MulticlassClassificationPromptTemplate\n",
        "from evidently.core.datasets import DatasetColumn\n",
        "from evidently.presets import TextEvals\n",
        "from evidently.metrics import CategoryCount, OutRangeValueCount\n",
        "from evidently.tests import eq,gte,lte\n",
        "from evidently.ui.workspace import CloudWorkspace"
      ],
      "metadata": {
        "id": "uAEYzoOO1DTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Part 1 A very basic example\n",
        "data = [\n",
        "    [\"What is the capital of France\",\"The capital of France is Paris\"],\n",
        "    [\"Can Penguins fly \",\"No Penguins can't fly but they are excellent swimmers\"],\n",
        "    [\"Help me withe the homework \",\"I 'm here to guide you but I can't do your homwroek for you\"],\n",
        "    [\"Is water wet\",\"Yes water is considered wet because it makes things wet\"],\n",
        "    [\"Do fish sleep\",\"Yes , fish do sleep , though not in the same way as humans do\"],\n",
        "    [\"What is 2+2\",\"2+2 equals 4\"],\n",
        "    {\"Is the Earth flat?\",\"No earth is a sphere\"},\n",
        "    [\"Can dogs talk\",\"Dogs can't talk like humans , but then  can bark , growl etc\"],\n",
        "    [\"What's your name \",\"I'm a virtual bot assistant bot.\"],\n",
        "    [\"Are bananas berries? \",\"Yes, botnaically speaking , bananas are classified as berries\"]\n",
        "]\n",
        "colums = [\"questions\",\"answer\"]\n",
        "eval_data = pd.DataFrame(data,columns=colums)"
      ],
      "metadata": {
        "id": "lYxbZjCr219m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth',None)"
      ],
      "metadata": {
        "id": "ZciJBToz5oMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_data.head()"
      ],
      "metadata": {
        "id": "E2YKomV551wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "definition = DataDefinition(text_columns=[\"question\",\"answer\"])"
      ],
      "metadata": {
        "id": "YxdwSsQl7QpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_df = Dataset.from_pandas(\n",
        "    pd.DataFrame(eval_data),\n",
        "    data_definition = definition\n",
        ")"
      ],
      "metadata": {
        "id": "aNNojYPX60NE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#descriptor for evaluating LLM. The below descriptor is for evaluating answer length\n",
        "eval_df.add_descriptors(descriptors=[TextLength(\"answer\", alias = \"Answer Length\")])"
      ],
      "metadata": {
        "id": "6abtE-zm7v8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_df.as_dataframe()"
      ],
      "metadata": {
        "id": "6ahxzaJY8Oef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Descriptor tests\n",
        "eval_df = Dataset.from_pandas(\n",
        "    pd.DataFrame(eval_data),\n",
        "    data_definition = definition,\n",
        "    descriptors = [TextLength(\"answer\", alias = \"Answer Length\",\n",
        "                   tests = [gte(100, alias = \"Answer is too long\")])])\n",
        "eval_df.as_dataframe()"
      ],
      "metadata": {
        "id": "7IYr18tI-EBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#report\n",
        "report = Report([TextEvals()])\n",
        "my_eval = report.run(eval_df)"
      ],
      "metadata": {
        "id": "Rk-C5Ws3BZV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_eval"
      ],
      "metadata": {
        "id": "_CcCUZNkBmx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Part 2 Reference-based-evals\n",
        "#Generate a toy dataset . Let's imgagine Q&A (RAG) use case where the system generates the  response based on the retrieved context\n",
        "import pandas as pd\n",
        "eval_data = pd.DataFrame([\n",
        "    {\n",
        "    \"question\": \"Will my transaction go through as I don't have enough funds?\",\n",
        "    \"context\":\"Overdraft protection allows transactions to be completed even if acocunt balance is insufficient\",\n",
        "    \"answer\": \"Yes , your transaction will go through if overdraft is enabled , but a $35 fee will apply\",\n",
        "    \"reference_answer\":\"Yes , with overdraft protection , your transcation will complete , but you will be charged $35.\"},\n",
        "    {\n",
        "    \"question\": \"How do I block my card if it's lost?\",\n",
        "    \"context\":\"To block a lost or stolen card users should immediately navigate to the Cards section in the FinBot app\",\n",
        "    \"answer\": \"Go to the cards section , select your card and tap 'block card' , to block instantly\",\n",
        "    \"reference_answer\":\"Open the app , go to cards , choose your cards and tap 'Block Card'. Blocking is immediate\"},\n",
        "    {\n",
        "    \"question\": \"Do you offer loans in Argetina?\",\n",
        "    \"context\":\"Finbot currently offers loans in 20+ locations , including the US , Canada and selected EU countries\",\n",
        "    \"answer\": \"Yes , Finbot offers personal loans in Argentina with competitive interest rates\",\n",
        "    \"reference_answer\":\"No , Finbot does not currently offer personal loans in Argentina\"\n",
        "    }\n",
        "\n",
        "  ])"
      ],
      "metadata": {
        "id": "eh8JMJ_ICjV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "golden_df = eval_data[[\"question\",\"reference_answer\"]].copy()\n",
        "golden_df.head()"
      ],
      "metadata": {
        "id": "wW9WsJ2SGnuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_data.head()"
      ],
      "metadata": {
        "id": "_9fcKCj1HeMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reference Based Evals\n",
        "#Deterministic\n",
        "definition = DataDefinition(text_columns=[\"question\",\"context\",\"answer\",\"reference_answer\"])\n",
        "eval_df = Dataset.from_pandas(\n",
        "    pd.DataFrame(eval_data),\n",
        "    data_definition = definition,\n",
        "    descriptors=[ExactMatch(columns = [\"answer\",\"reference_answer\"], alias = \"Exact Match\")]\n",
        "    )"
      ],
      "metadata": {
        "id": "Qu8ndSsJHluw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_df.as_dataframe()"
      ],
      "metadata": {
        "id": "K7hItaUlJHoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate semantic similarity\n",
        "eval_df.add_descriptors(descriptors=[SemanticSimilarity(columns=[\"answer\",\"reference_answer\"],alias=\"Semantic Similarity\"),\n",
        "                                     BERTScore(columns=[\"answer\",\"reference_answer\"],alias=\"BERTScore\")])\n",
        "eval_df.as_dataframe()"
      ],
      "metadata": {
        "id": "klAk_T9AJixr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LLM-As-A-Judge --------->USING REFERENCE/GT  - QUALITATIVE EVALS\n",
        "import os\n",
        "from google.colab import userdata\n",
        "# Access the API key from Colab's secrets manager\n",
        "openai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
      ],
      "metadata": {
        "id": "G002Zl15LwM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_df.add_descriptors(descriptors=[CorrectnessLLMEval(\"answer\",target_output=\"reference_answer\")])\n",
        "eval_df.as_dataframe()"
      ],
      "metadata": {
        "id": "-luKkA3zL4xS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create your own custom Judge prompt\n",
        "\n",
        "eval_df_2 = Dataset.from_pandas(\n",
        "    pd.DataFrame(eval_data),\n",
        "    data_definition = definition,)"
      ],
      "metadata": {
        "id": "mituIsguNzS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corerctness_multiclass = MulticlassClassificationPromptTemplate(\n",
        "    pre_messages = [(\"system\",\"You are a judge that evaluates the factual alignment of two chatbot answers\")],\n",
        "    criteria = \"\"\" You are given new answer and a reference answer . Classify the new answer based on how it compares to reference.\n",
        "    ===\n",
        "    Reference: {reference_answer}\"\"\",\n",
        "    category_column = {\n",
        "        \"fully_correct\":\"The answer matches the reference in all factual and semantic details\",\n",
        "        \"incomplete\":\"The answer is correct in what it says but leaves out details from the reference\",\n",
        "        \"adds_claims\":\"The answer does not contradict reference but introduces new claims not supported by reference\",\n",
        "        \"contradictory\":\"The answer contradicts specific facts or meaning in the reference\"\n",
        "        \"\"\n",
        "    },\n",
        "    uncertainity = \"unknown\",\n",
        "    include_reasoning = True,\n",
        "    include_scores = False\n",
        ")"
      ],
      "metadata": {
        "id": "t5PaRENEOFlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_df_2.add_descriptors(descriptors=[LLMEval(\"answer\",template=corerctness_multiclass, additional_columns={\"reference_answer\":\"reference_answer\"},\n",
        "                                               provider =\"openai\",\n",
        "                                               model =\"gpt-4o-mini\",\n",
        "                                               alias = \"Multi-class correctness\"\n",
        "                                               )\n",
        "])"
      ],
      "metadata": {
        "id": "Nnip06k5QHTy"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_df_2.as_dataframe()"
      ],
      "metadata": {
        "id": "22h6Y-mIRNbg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 976
        },
        "outputId": "0cdadd5a-b79f-4167-e8e9-cebe22992d5e"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                       question  \\\n",
              "0  Will my transaction go through as I don't have enough funds?   \n",
              "1                          How do I block my card if it's lost?   \n",
              "2                               Do you offer loans in Argetina?   \n",
              "\n",
              "                                                                                                   context  \\\n",
              "0         Overdraft protection allows transactions to be completed even if acocunt balance is insufficient   \n",
              "1  To block a lost or stolen card users should immediately navigate to the Cards section in the FinBot app   \n",
              "2     Finbot currently offers loans in 20+ locations , including the US , Canada and selected EU countries   \n",
              "\n",
              "                                                                                      answer  \\\n",
              "0  Yes , your transaction will go through if overdraft is enabled , but a $35 fee will apply   \n",
              "1       Go to the cards section , select your card and tap 'block card' , to block instantly   \n",
              "2            Yes , Finbot offers personal loans in Argentina with competitive interest rates   \n",
              "\n",
              "                                                                                  reference_answer  \\\n",
              "0  Yes , with overdraft protection , your transcation will complete , but you will be charged $35.   \n",
              "1       Open the app , go to cards , choose your cards and tap 'Block Card'. Blocking is immediate   \n",
              "2                                 No , Finbot does not currently offer personal loans in Argentina   \n",
              "\n",
              "  Multi-class correctness  \\\n",
              "0                    SAME   \n",
              "1                    SAME   \n",
              "2              INACCURATE   \n",
              "\n",
              "                                                                                                                                                                                                                                Multi-class correctness reasoning  \\\n",
              "0             The new answer provides the same information as the reference answer, indicating that a transaction will go through with overdraft and that a $35 fee will apply. Although the wording is slightly different, the essential details are consistent.   \n",
              "1  The new answer provides a similar step-by-step process for blocking a card, including going to the cards section, selecting the card, and tapping 'block card'. It also specifies that blocking is done instantly, aligning closely with the reference answer.   \n",
              "2                                                                                The new answer directly contradicts the reference answer, which states that Finbot does not offer personal loans in Argentina. Therefore, the new answer is factually incorrect.   \n",
              "\n",
              "  Multi-class correctness_1  \\\n",
              "0                      SAME   \n",
              "1                     ALIGN   \n",
              "2                     FALSE   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                           Multi-class correctness reasoning_1  \\\n",
              "0                                                                                                                                                                        The new answer conveys the same information as the reference answer, stating that the transaction will go through if overdraft is enabled and that there will be a $35 fee applied. The wording is slightly different, but the meaning is consistent.   \n",
              "1  The new answer provides essentially the same steps and outcome as the reference answer. It instructs the user to go to the cards section, select their card, and tap 'block card', which aligns with the reference's instruction to go to cards, choose the card, and tap 'Block Card'. Both specify that blocking is immediate, although 'instantly' is used in the new answer. Therefore, the factual content is aligned.   \n",
              "2                                                                                                                                                                                                                                                        The new answer contradicts the reference answer by stating that Finbot does offer personal loans in Argentina, whereas the reference clearly states that it does not.   \n",
              "\n",
              "  Multi-class correctness_2  \\\n",
              "0                     MATCH   \n",
              "1                   aligned   \n",
              "2                 incorrect   \n",
              "\n",
              "                                                                                                                                                                                                                                                               Multi-class correctness reasoning_2  \n",
              "0  The new answer closely matches the reference answer in meaning and content. Both indicate that a transaction will be completed if overdraft protection is enabled, and both mention that a $35 fee will apply. The phrasing is slightly different, but the essential information is consistent.  \n",
              "1                                              The new answer provides similar instructions to the reference answer, specifying to go to the cards section, select the card, and tap 'block card' to block the card instantly. Both answers convey the same essential process for blocking a card.  \n",
              "2                                                                                                 The new answer asserts that Finbot offers personal loans in Argentina, which directly contradicts the reference answer stating that Finbot does not currently offer personal loans in Argentina.  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ee505ddc-bb14-4e35-b8df-e93a699fa5a1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>context</th>\n",
              "      <th>answer</th>\n",
              "      <th>reference_answer</th>\n",
              "      <th>Multi-class correctness</th>\n",
              "      <th>Multi-class correctness reasoning</th>\n",
              "      <th>Multi-class correctness_1</th>\n",
              "      <th>Multi-class correctness reasoning_1</th>\n",
              "      <th>Multi-class correctness_2</th>\n",
              "      <th>Multi-class correctness reasoning_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Will my transaction go through as I don't have enough funds?</td>\n",
              "      <td>Overdraft protection allows transactions to be completed even if acocunt balance is insufficient</td>\n",
              "      <td>Yes , your transaction will go through if overdraft is enabled , but a $35 fee will apply</td>\n",
              "      <td>Yes , with overdraft protection , your transcation will complete , but you will be charged $35.</td>\n",
              "      <td>SAME</td>\n",
              "      <td>The new answer provides the same information as the reference answer, indicating that a transaction will go through with overdraft and that a $35 fee will apply. Although the wording is slightly different, the essential details are consistent.</td>\n",
              "      <td>SAME</td>\n",
              "      <td>The new answer conveys the same information as the reference answer, stating that the transaction will go through if overdraft is enabled and that there will be a $35 fee applied. The wording is slightly different, but the meaning is consistent.</td>\n",
              "      <td>MATCH</td>\n",
              "      <td>The new answer closely matches the reference answer in meaning and content. Both indicate that a transaction will be completed if overdraft protection is enabled, and both mention that a $35 fee will apply. The phrasing is slightly different, but the essential information is consistent.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How do I block my card if it's lost?</td>\n",
              "      <td>To block a lost or stolen card users should immediately navigate to the Cards section in the FinBot app</td>\n",
              "      <td>Go to the cards section , select your card and tap 'block card' , to block instantly</td>\n",
              "      <td>Open the app , go to cards , choose your cards and tap 'Block Card'. Blocking is immediate</td>\n",
              "      <td>SAME</td>\n",
              "      <td>The new answer provides a similar step-by-step process for blocking a card, including going to the cards section, selecting the card, and tapping 'block card'. It also specifies that blocking is done instantly, aligning closely with the reference answer.</td>\n",
              "      <td>ALIGN</td>\n",
              "      <td>The new answer provides essentially the same steps and outcome as the reference answer. It instructs the user to go to the cards section, select their card, and tap 'block card', which aligns with the reference's instruction to go to cards, choose the card, and tap 'Block Card'. Both specify that blocking is immediate, although 'instantly' is used in the new answer. Therefore, the factual content is aligned.</td>\n",
              "      <td>aligned</td>\n",
              "      <td>The new answer provides similar instructions to the reference answer, specifying to go to the cards section, select the card, and tap 'block card' to block the card instantly. Both answers convey the same essential process for blocking a card.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Do you offer loans in Argetina?</td>\n",
              "      <td>Finbot currently offers loans in 20+ locations , including the US , Canada and selected EU countries</td>\n",
              "      <td>Yes , Finbot offers personal loans in Argentina with competitive interest rates</td>\n",
              "      <td>No , Finbot does not currently offer personal loans in Argentina</td>\n",
              "      <td>INACCURATE</td>\n",
              "      <td>The new answer directly contradicts the reference answer, which states that Finbot does not offer personal loans in Argentina. Therefore, the new answer is factually incorrect.</td>\n",
              "      <td>FALSE</td>\n",
              "      <td>The new answer contradicts the reference answer by stating that Finbot does offer personal loans in Argentina, whereas the reference clearly states that it does not.</td>\n",
              "      <td>incorrect</td>\n",
              "      <td>The new answer asserts that Finbot offers personal loans in Argentina, which directly contradicts the reference answer stating that Finbot does not currently offer personal loans in Argentina.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee505ddc-bb14-4e35-b8df-e93a699fa5a1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ee505ddc-bb14-4e35-b8df-e93a699fa5a1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ee505ddc-bb14-4e35-b8df-e93a699fa5a1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ddef53e8-ebd3-4d3d-b2e0-7f05e068544f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ddef53e8-ebd3-4d3d-b2e0-7f05e068544f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ddef53e8-ebd3-4d3d-b2e0-7f05e068544f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"eval_df_2\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Will my transaction go through as I don't have enough funds?\",\n          \"How do I block my card if it's lost?\",\n          \"Do you offer loans in Argetina?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Overdraft protection allows transactions to be completed even if acocunt balance is insufficient\",\n          \"To block a lost or stolen card users should immediately navigate to the Cards section in the FinBot app\",\n          \"Finbot currently offers loans in 20+ locations , including the US , Canada and selected EU countries\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Yes , your transaction will go through if overdraft is enabled , but a $35 fee will apply\",\n          \"Go to the cards section , select your card and tap 'block card' , to block instantly\",\n          \"Yes , Finbot offers personal loans in Argentina with competitive interest rates\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reference_answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Yes , with overdraft protection , your transcation will complete , but you will be charged $35.\",\n          \"Open the app , go to cards , choose your cards and tap 'Block Card'. Blocking is immediate\",\n          \"No , Finbot does not currently offer personal loans in Argentina\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Multi-class correctness\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"INACCURATE\",\n          \"SAME\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Multi-class correctness reasoning\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"The new answer provides the same information as the reference answer, indicating that a transaction will go through with overdraft and that a $35 fee will apply. Although the wording is slightly different, the essential details are consistent.\",\n          \"The new answer provides a similar step-by-step process for blocking a card, including going to the cards section, selecting the card, and tapping 'block card'. It also specifies that blocking is done instantly, aligning closely with the reference answer.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Multi-class correctness_1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"SAME\",\n          \"ALIGN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Multi-class correctness reasoning_1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"The new answer conveys the same information as the reference answer, stating that the transaction will go through if overdraft is enabled and that there will be a $35 fee applied. The wording is slightly different, but the meaning is consistent.\",\n          \"The new answer provides essentially the same steps and outcome as the reference answer. It instructs the user to go to the cards section, select their card, and tap 'block card', which aligns with the reference's instruction to go to cards, choose the card, and tap 'Block Card'. Both specify that blocking is immediate, although 'instantly' is used in the new answer. Therefore, the factual content is aligned.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Multi-class correctness_2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"MATCH\",\n          \"aligned\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Multi-class correctness reasoning_2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"The new answer closely matches the reference answer in meaning and content. Both indicate that a transaction will be completed if overdraft protection is enabled, and both mention that a $35 fee will apply. The phrasing is slightly different, but the essential information is consistent.\",\n          \"The new answer provides similar instructions to the reference answer, specifying to go to the cards section, select the card, and tap 'block card' to block the card instantly. Both answers convey the same essential process for blocking a card.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REFERENCE FREE EVALS\n",
        "#reference free evals - there is no GT\n",
        "#run when there is no answer or hard to prepare answer\n",
        "\n"
      ],
      "metadata": {
        "id": "EVBOGsBv4XRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reference free evals - there is no GT\n",
        "#run when there is no answer or hard to prepare answer\n",
        "prod_data = eval_data[[\"question\",\"context\",\"answer\"]].copy()\n",
        "prod_data.head()"
      ],
      "metadata": {
        "id": "j5xQE-WpThBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "definition = DataDefinition(text_columns=[\"question\",\"context\",\"answer\"])\n",
        "prod_df = Dataset.from_pandas(\n",
        "    pd.DataFrame(prod_data),\n",
        "    data_definition = definition,\n",
        ")"
      ],
      "metadata": {
        "id": "cuVWJwY3XCbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Word presence in the generated answer or not / or check if the forbidden words are present in the response\n",
        "#or you can use Contains  , a custom RegEX etc\n",
        "\n",
        "prod_df.add_descriptors(descriptors=[\n",
        "    IncludesWords(\"answer\",words_list = [\"hello\",\"hi\",\"good_afternoon\"], mode=\"any\", alias =\"Says hi\"),\n",
        "    IncludesWords(\"answer\",words_list = [\"sorry\",\"apologies\",\"apologize\",\"cannot\",\"afraid\"], mode=\"any\", alias =\"Declines\"),\n",
        "])\n",
        "prod_df.as_dataframe()"
      ],
      "metadata": {
        "id": "X5aVHyq4XPbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TEXT STATS - can be used to check if there is a certain change in response length\n",
        "prod_df = Dataset.from_pandas(\n",
        "    pd.DataFrame(prod_data),\n",
        "    data_definition = definition,\n",
        "    descriptors =[SentenceCount(\"answer\", alias = \"Sentence_Count\")]\n",
        ")\n",
        "prod_df.as_dataframe()"
      ],
      "metadata": {
        "id": "blF1YSlQYIPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUANTITATIVE EVALS\n",
        "\n",
        "Natural Language Based Metrics such as BLEU , ROUGE , BERTScore , Perplexity ,\n",
        "Diversity , Racial Bias , WEAT etc."
      ],
      "metadata": {
        "id": "Vd1F0YcG4qC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate Context Retreival Effectiveness via metrics such as Contextual Recall , Precision\n",
        "#use BERTScore for this\n",
        "#challenge is that BERT Score will not work for long sentences as BERT has context window of size = 512 .. then what to use\n",
        "#BERTScore - Measures the semantic similarity of the two sentences. Higher score indicates better match\n",
        "#BLEU (Precision) metric is used for evaluating transalation. Tokens generated by model match with ground truth. Higher score indicates better match\n",
        "#ROUGE is used to evaluate text summarization - Recall Oriented Unigram Gist Evaluation ->#Objective of ROUGE is to measure /evaluate the longest (unigram , bigram , n-gram etc.)overlap between the generated text and reference text in terms of unigrams. Higher means the better\n",
        "#Perplexity - Metric to measure the answer coherence of LLM . LLM generated text .... Lower perplexity means LLM is generating a coherent response\n",
        "#Diversity - Metric to measure the diversity in the generated text . Higher diversity means large vocab of LLM and that this is good . Formula is unique-n-grams/total n-grams\n",
        "#Racial Bias - Offensive Language\n",
        "#WEAT\n",
        "#Fact Checking Algos\n",
        "#Burstiness\n"
      ],
      "metadata": {
        "id": "ljh0lw7EZtWI"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bert-score evaluate\n",
        "!pip install rouge_score sacrebleu nltk streamlit"
      ],
      "metadata": {
        "id": "Vyy1VLZ16x95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bert_score import score\n",
        "import evaluate"
      ],
      "metadata": {
        "id": "Jl40Lu-V7bA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_text = [\"The quick brown fox jumps over the lazy dog.\"]\n",
        "reference_text = [\"The fast brown fox jumps over the sleepy dog.\"]\n",
        "P, R, F1 = score(generated_text, reference_text, lang=\"en\", verbose=True)\n",
        "print(f\"Precision :{P.mean()}, Recall {R.mean()},F1 {F1.mean()}\")\n",
        "\n",
        "bleu_metric = evaluate.load(\"bleu\")\n",
        "bleu_score = bleu_metric.compute(predictions=generated_text, references=reference_text)\n",
        "print(f\"BLEU Score: {bleu_score['bleu']}\")\n",
        "\n",
        "rouge_metric = evaluate.load(\"rouge\")\n",
        "rouge_score = rouge_metric.compute(predictions=generated_text, references=reference_text)\n",
        "print(f\"ROUGE Score: {rouge_score['rougeL']}\")"
      ],
      "metadata": {
        "id": "x218UW5R78fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fc47283"
      },
      "source": [
        "from bert_score import score\n",
        "\n",
        "# Extract context and answer columns as lists\n",
        "contexts = prod_data[\"context\"].tolist()\n",
        "answers = prod_data[\"answer\"].tolist()\n",
        "\n",
        "# Calculate BERTScore\n",
        "P, R, F1 = score(answers, contexts, lang=\"en\", verbose=True)\n",
        "\n",
        "# Display the precision, recall, and F1 scores\n",
        "print(\"BERTScore Precision:\", P)\n",
        "print(\"BERTScore Recall:\", R)\n",
        "print(\"BERTScore F1 Score:\", F1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Code for measuring perplexity\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "#assign the EOS token as the padding token\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "bhptknOfcxQU"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_perplexity(input_texts):\n",
        "  inputs = tokenizer(\n",
        "      input_texts,\n",
        "      return_tensors=\"pt\",\n",
        "      padding=True,\n",
        "      truncation=True\n",
        "      )\n",
        "  input_ids = inputs[\"input_ids\"]\n",
        "  attention_mask = inputs[\"attention_mask\"] #telling the LLM on what tokens to pay attention to\n",
        "\n",
        "  #solid code as this shows the autoregressive loss ....\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs = model(input_ids, attention_mask=attention_mask)\n",
        "    logits = outputs.logits\n",
        "  shift_logits = logits[..., :-1, :].contiguous() #shift the logits by\n",
        "  shift_labels = input_ids[..., 1:].contiguous()\n",
        "  #shift the logits so that these become the token to be predicted . LLM predict the probability distribution of all the tokens from the vocabulary\n",
        "\n",
        "  #shift_logits = logits[:,:-1,:]\n",
        "  #shift_labels = input_ids[:,1:]\n",
        "\n",
        "  log_probs = torch.nn.functional.log_softmax(shift_logits, dim=-1)\n",
        "  target_log_probs = log_probs.gather(dim=-1, index= shift_labels.unsqueeze(-1)).squeeze(-1)\n",
        "  target_log_probs = target_log_probs * attention_mask[:, 1:].to(log_probs.dtype)\n",
        "  negative_log_likelihood = -target_log_probs.sum(dim=-1) / attention_mask[:,1:].sum(dim=-1)\n",
        "  perplexity = torch.exp(negative_log_likelihood)\n",
        "  mean_perplexity_score = torch.mean(perplexity)\n",
        "\n",
        "  return{\n",
        "      \"perplexity_scores\":perplexity.tolist(),\n",
        "      \"perplexities_mean\":mean_perplexity_score.item()\n",
        "  }\n",
        ""
      ],
      "metadata": {
        "id": "1RD_JgAUep3P"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculating the perplexities score\n",
        "example_text = [\n",
        "    \"Once upon a time , there was a brave knight\",\n",
        "    \"In a galaxy far , far away , a new adventure began\"\n",
        "]\n",
        "#compute perplexity\n",
        "perplexity_scores = compute_perplexity(example_text)\n",
        "print(perplexity_scores[\"perplexity_scores\"],perplexity_scores[\"perplexities_mean\"] )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAklAYKEiI59",
        "outputId": "3d4009e7-f5ad-434c-fa41-0d2e9bdc0a03"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[51.4720573425293, 94.8211441040039] 73.14659881591797\n"
          ]
        }
      ]
    }
  ]
}